---
title: "Data processing"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### (1) sort and index bam file 
`while read -a line
do
samtools sort $line  > ${line%%.*}.sort.bam & 
done < $1` 
`while read -a line
do
samtools index $line  & 
done < $1`    

### (2) transform bam file to bedgraph file 
`while read -a line
do samtools bedcov -Q 30  hg19_1k.bed $line  > ${line%%.*}.q30.bedgraph & 
done < bam_list`    

### (3)  bedgraph file normalization 
`library(data.table)` 

`files <- list.files("./bedgraph/", pattern = "*q30.1k", full.names = T)`

`for (i  in 1:length(files)) {`
  `mat <- fread(files[i])`
  
  `mat$V6 <- as.numeric(mat$V6)/sum(as.numeric(mat$V6)) * 100000000`
  
  `sample <- basename(files[i])`
  
  `write.table(mat, paste0("./bedgraph/", sample, ".norm.BedGraph"),` 
              `row.names = F, col.names = F, quote = F, sep = "\t")`
              
`}`

### (4)  calculate log2nHi-C/Hi-C and log2NS/WGS 
`setwd("./dnabam/bedgraph/")`

`wgs1 <- fread("hela_wgs1.q30.1k.bedgraph.norm.BedGraph")`

`wgs2 <- fread("hela_wgs2.q30.1k.bedgraph.norm.BedGraph")`

`n1 <- fread("hela_n1_wgs.q30.1k.bedgraph.norm.BedGraph")`

`n2 <- fread("hela_n2_wgs.q30.1k.bedgraph.norm.BedGraph")`

`wgs <- cbind(wgs1[,c(1:3,4)], wgs2[,4])`

`wgs$mean <- rowMeans(wgs[,3:4])`

`mat <- cbind(wgs[,c(1,5)], n2[,4])`

`names(mat) <- c("chromosome", "position", "wgs","n2")`

`mat$ratio <- log2(mat$n2/mat$wgs)`

`loci <- c(which(is.na(mat$ratio)), which(is.infinite(mat$ratio)))`

`mat$ratio[loci] <- mat$n2[loci] - mat$wgs[loci]`

`mat <- mat[-which(mat$wgs == 0 & mat$n2 == 0), ]`

### (5)  HMM call NAD 
`source('getNAD.R')`

`wgmat <- split(mat, f = mat$chromosome)`

`wgregions <- data.frame(chr = as.character(), start = as.numeric(), end = as.numeric())`

`for(i in 1:23){`

  `if(i == 23){chr = "chrX"}`

  `else{chr = paste0("chr", i)}`
  
  `chrmat <- wgmat[[chr]]`
  
  `wgregions <- rbind(wgregions, getNAD(chrmat))`
`}`

### (6)  Merge and filter NAD 
`
while read -a line
do bedtools merge -d 100000 -i $line > merge_$line
done < nad.list
`
`while read -a line
do awk '$3-$2>=10000' $line.merged.bed > $line.merged.filter.bed
done <  nad_merge.list`